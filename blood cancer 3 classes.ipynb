{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46bf8b75-1277-4099-852d-f809800bcf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a52339c-6f1e-4264-8093-9b4287b7cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image dimensions and other parameters\n",
    "image_size = (150, 150)\n",
    "input_shape = (150, 150, 3)  # 3 channels for RGB images\n",
    "batch_size = 64\n",
    "epochs = 15\n",
    "num_classes = 4 \n",
    "data_dir = 'D:/Palak/MIT/Semester 6/Mini Project/CNN model/Preprocessed dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3497c1c-b96d-465a-bf0b-0b441c161840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and split into training and validation sets\n",
    "def load_and_split_dataset(data_dir, test_size=0.2):\n",
    "    # Load dataset using image_dataset_from_directory\n",
    "    dataset = image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        labels='inferred',  # Automatically infer labels from subdirectory names\n",
    "        label_mode='int',\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "     # Split the dataset into training and validation sets\n",
    "    train_dataset, val_dataset = train_test_split(\n",
    "        dataset, test_size=test_size, \n",
    "        random_state=42, \n",
    "        shuffle=True\n",
    "    )\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abbd2f97-d2b3-4758-8166-e1f9fdd5c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training data\n",
    "def augment_data(train_dataset):\n",
    "    # Create an instance of ImageDataGenerator\n",
    "    data_augmentor = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Apply augmentation to training data\n",
    "    augmented_train_dataset = data_augmentor.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='sparse',\n",
    "        subset='training'\n",
    "    )\n",
    "    \n",
    "    return augmented_train_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96f618c4-31ef-420a-b1fc-a60ad59d95a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images in the dataset\n",
    "def normalize_dataset(dataset):\n",
    "    # Normalize pixel values to range [0, 1]\n",
    "    normalized_dataset = dataset.map(lambda x, y: (x / 255.0, y))\n",
    "    return normalized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d62094a-c7e8-4d07-8677-a001f7f9f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main script\n",
    "def main():\n",
    "    # Load and split dataset\n",
    "    train_dataset, val_dataset = load_and_split_dataset(data_dir, image_size, test_size = 0.2)\n",
    "    \n",
    "    # Augment data for training\n",
    "    augmented_train_dataset = augment_data(train_dataset)\n",
    "    \n",
    "    # Normalize training and validation datasets\n",
    "    normalized_train_dataset = normalize_dataset(augmented_train_dataset)\n",
    "    normalized_val_dataset = normalize_dataset(val_dataset)\n",
    "    \n",
    "    # At this point, normalized_train_dataset and normalized_val_dataset are ready to be used for training your CNN model\n",
    "    print(\"Data pre-processing completed.\")\n",
    "    \n",
    "    # Further steps: Build your CNN model and train it using the pre-processed datasets\n",
    "    # Use normalized_train_dataset for training and normalized_val_dataset for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c04981-6ba7-4910-9b30-58a0ac3fa1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data using ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23e57846-f3de-4b5c-a27a-b8ff92b68ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Palak\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:146: UserWarning: Using \".tiff\" files with multiple bands will cause distortion. Please verify your output.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19369 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'blood cancer dataset',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbc05685-2408-458a-82e4-ecc0c4746570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19369 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'blood cancer dataset',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4b0a6b2-22ee-438b-a357-fb6ca6dbbdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Palak\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# Build CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')  # Output layer for classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a420767-467b-4ca5-853f-c786200e38ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a348986-cf75-482d-a4c9-c84a770d8dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Palak\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/302\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6:33\u001b[0m 2s/step - accuracy: 0.7890 - loss: 0.5551"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "history = model.fit( \n",
    "    train_generator, \n",
    "    steps_per_epoch=train_generator.samples // batch_size, \n",
    "    epochs=epochs, \n",
    "    validation_data=validation_generator, \n",
    "    validation_steps=validation_generator.samples // batch_size \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7826ad99-e3b6-4739-a030-d333de129139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 370ms/step - accuracy: 0.9997 - loss: 0.0040\n",
      "Test Loss: 0.0023880978114902973\n",
      "Test Accuracy: 0.9996446967124939\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "score = model.evaluate(validation_generator)\n",
    "print(\"Test Loss:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
